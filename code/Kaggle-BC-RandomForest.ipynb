{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting plt layout\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/matlp/Desktop/Nova Pasta/KaggleBC/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting independent and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset\n",
    "X = X.drop(X.columns[[1, 32]], axis=1)\n",
    "y = dataset[['diagnosis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing target variable\n",
    "\n",
    "M = 1,\n",
    "B = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y.replace('M', 1).replace('B', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(X.filter(regex='^(?=(radius|perimeter)).*', axis=1).columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting CV and test datasets\n",
    "\n",
    "Further analysis will be based only on CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Separating CV and test datasets\n",
    "X_cv, X_test, y_cv, y_test = tts(X, y, test_size = 0.1, random_state=1)\n",
    "\n",
    "## Separating Train and Validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = tts(X_cv, y_cv, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SC = StandardScaler()\n",
    "X_cv_N = pd.DataFrame(SC.fit_transform(X_cv), columns=X_cv.columns)\n",
    "X_test_N = pd.DataFrame(SC.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4- Fitting classifier\n",
    "\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without CV (direct model application)\n",
    "\n",
    "##### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matlp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rtc = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=1)\n",
    "rtc.fit(X_cv_N, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature: area_worst (0.184797)\n",
      "2. feature: concave points_mean (0.148924)\n",
      "3. feature: concavity_mean (0.130332)\n",
      "4. feature: concave points_worst (0.091346)\n",
      "5. feature: concavity_worst (0.077628)\n",
      "6. feature: area_se (0.071919)\n",
      "7. feature: area_mean (0.051836)\n",
      "8. feature: smoothness_worst (0.048815)\n",
      "9. feature: compactness_mean (0.047531)\n",
      "10. feature: concavity_se (0.023527)\n",
      "11. feature: texture_worst (0.017272)\n",
      "12. feature: texture_mean (0.016815)\n",
      "13. feature: concave points_se (0.012851)\n",
      "14. feature: fractal_dimension_mean (0.010979)\n",
      "15. feature: symmetry_worst (0.010203)\n",
      "16. feature: id (0.009394)\n",
      "17. feature: compactness_se (0.008925)\n",
      "18. feature: symmetry_se (0.008155)\n",
      "19. feature: symmetry_mean (0.006572)\n",
      "20. feature: fractal_dimension_worst (0.006521)\n",
      "21. feature: texture_se (0.004582)\n",
      "22. feature: fractal_dimension_se (0.004181)\n",
      "23. feature: compactness_worst (0.003307)\n",
      "24. feature: smoothness_mean (0.003161)\n",
      "25. feature: smoothness_se (0.000424)\n"
     ]
    }
   ],
   "source": [
    "importances = rtc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rtc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_cv_N.shape[1]):\n",
    "    print(\"%d. feature: \"%(f+1) + X_cv_N.columns[indices[f]]+ \" (%f)\" % (importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's close to what we expected after the feature exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_rtc = rtc.predict(X_test_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97        34\n",
      "          1       1.00      0.91      0.95        23\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_rtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  0],\n",
       "       [ 2, 21]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_rtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_rtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
